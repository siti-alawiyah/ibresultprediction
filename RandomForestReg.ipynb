{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Model",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM7FzRxb1Sy2ZUUd+JcBdPm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siti-alawiyah/ibresultprediction/blob/main/RandomForestReg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN6LipTY2xrC"
      },
      "source": [
        "# imports\n",
        "# ignore future warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn import metrics\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow9AnsRfoMQe"
      },
      "source": [
        "# links to dataset\n",
        "URL1 = \"https://raw.githubusercontent.com/siti-alawiyah/ibresultprediction/main/data/2020IB.csv\"\n",
        "URL2 = \"https://raw.githubusercontent.com/siti-alawiyah/ibresultprediction/main/data/2019IB.csv\"\n",
        "URL3 = \"https://raw.githubusercontent.com/siti-alawiyah/ibresultprediction/main/data/2018IB.csv\"   \n",
        "URL4 = \"https://raw.githubusercontent.com/siti-alawiyah/ibresultprediction/main/data/2017IB.csv\"      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WcygR0d9QaI"
      },
      "source": [
        "# read the url for the datasets\n",
        "df20 = pd.read_csv(URL1)\n",
        "df19 = pd.read_csv(URL2)\n",
        "df18 = pd.read_csv(URL3)\n",
        "df17 = pd.read_csv(URL4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ffrhg1IwoMXh"
      },
      "source": [
        "# getting the columns prior for modelling\n",
        "col_name = [\"Ma Std\",\"Ma Teacher\",\"Ma ATL\",\"Ma Compl. Of Work\",\"Ma Sub Achievement\",\"Predicted Grade\",\"Actual Grade\",\"Scaled Total\"]\n",
        "\n",
        "df20 = df20[col_name]\n",
        "df19 = df19[col_name]\n",
        "df18 = df18[col_name]\n",
        "df17 = df17[col_name]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-hFcORpoMaP"
      },
      "source": [
        "# combine the dataframes into 1 before modelling\n",
        "frames = [df20,df19,df18,df17]\n",
        "df = pd.concat(frames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj3w_HjEoMdA",
        "outputId": "d1f1046e-c704-4727-94cb-5a6b50dde327"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 692 entries, 0 to 178\n",
            "Data columns (total 8 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   Ma Std              657 non-null    object \n",
            " 1   Ma Teacher          657 non-null    object \n",
            " 2   Ma ATL              657 non-null    float64\n",
            " 3   Ma Compl. Of Work   654 non-null    float64\n",
            " 4   Ma Sub Achievement  657 non-null    float64\n",
            " 5   Predicted Grade     654 non-null    float64\n",
            " 6   Actual Grade        652 non-null    float64\n",
            " 7   Scaled Total        653 non-null    float64\n",
            "dtypes: float64(6), object(2)\n",
            "memory usage: 48.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oZJydJUoMfZ",
        "outputId": "bed15883-9bce-4672-da8f-b3aa7f416c59"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ma Std                35\n",
              "Ma Teacher            35\n",
              "Ma ATL                35\n",
              "Ma Compl. Of Work     38\n",
              "Ma Sub Achievement    35\n",
              "Predicted Grade       38\n",
              "Actual Grade          40\n",
              "Scaled Total          39\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knZyr35goMh5"
      },
      "source": [
        "#drop rows that have null values\n",
        "df.dropna(axis=0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XTFg8vzoovA",
        "outputId": "6df2acc9-03be-4949-d3ed-9fe81d71132b"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 650 entries, 0 to 177\n",
            "Data columns (total 8 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   Ma Std              650 non-null    object \n",
            " 1   Ma Teacher          650 non-null    object \n",
            " 2   Ma ATL              650 non-null    float64\n",
            " 3   Ma Compl. Of Work   650 non-null    float64\n",
            " 4   Ma Sub Achievement  650 non-null    float64\n",
            " 5   Predicted Grade     650 non-null    float64\n",
            " 6   Actual Grade        650 non-null    float64\n",
            " 7   Scaled Total        650 non-null    float64\n",
            "dtypes: float64(6), object(2)\n",
            "memory usage: 45.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8fxjbZmoo2F"
      },
      "source": [
        "# dummify Ma Std and Ma Teacher\n",
        "col= ['Ma Std','Ma Teacher']\n",
        "\n",
        "# Creaing dummies \n",
        "df= pd.get_dummies(columns=col, data=df,drop_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drm9FxtKoo4v"
      },
      "source": [
        "# create train test split \n",
        "X = df.drop(['Predicted Grade','Actual Grade'],axis=1)\n",
        "y = df['Actual Grade']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5lk95hZoo99"
      },
      "source": [
        "# functions for comparing models \n",
        "\n",
        "# RMSE function\n",
        "def rmse(model, X, y):\n",
        "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv = 5))\n",
        "    return(rmse.mean())\n",
        "\n",
        "#compare train, test, and cv score\n",
        "def display_r2(model, X_train, y_train, X_test, y_test):\n",
        "    print('Train Score: ', round(model.score(X_train,y_train),7))\n",
        "    print('Test Score: ', round(model.score(X_test, y_test),7))\n",
        "    print('Cross Val Score:', round(cross_val_score(model, X_test,y_test).mean(),7))\n",
        "\n",
        "# model comparisons\n",
        "model_dictionary = {}\n",
        "def add_model(name, model, X_test, y_test):\n",
        "    model_dictionary[name] = [round(rmse(model,X_test,y_test),7), #RMSE\n",
        "                              round(model.score(X_test, y_test),7)] #r2 score\n",
        "    return pd.DataFrame.from_dict(model_dictionary, orient = 'index', columns=['RMSE', 'R2 Score'])\n",
        "    \n",
        "# Plot Residuals and Predictions\n",
        "def plot_pred(model, X_test, y_test):\n",
        "    pred = model.predict(X_test)\n",
        "    \n",
        "    \n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,7))\n",
        "    \n",
        "    #Plot Residuals\n",
        "    ax1.set_title('Residuals Plot')\n",
        "    ax1.set(xlabel='Predicted values', ylabel='Residuals')\n",
        "    ax1.scatter(pred, y_test - pred)\n",
        "    ax1.hlines(y = 0, xmin = min(pred), xmax = max(pred), colors='red', linestyles='solid')\n",
        "    \n",
        "    #Plot Predictions\n",
        "    ax2.set_title('Predictions vs Actuals')\n",
        "    ax2.set(xlabel='Predicted values', ylabel='Actual Values')\n",
        "    ax2.scatter(pred, y_test)\n",
        "    \n",
        "    lims = [\n",
        "    np.min([ax2.get_xlim(), ax2.get_ylim()]),  # min of both axes\n",
        "    np.max([ax2.get_xlim(), ax2.get_ylim()]),  # max of both axes\n",
        "    ]\n",
        "    \n",
        "    ax2.plot(lims, lims, 'k-', c = 'red', zorder=0)\n",
        "                              \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baUC8qgyVyEX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}